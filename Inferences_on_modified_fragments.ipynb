{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import random\n",
    "import pickle\n",
    "import datetime\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "from scipy.stats import special_ortho_group\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "import itertools\n",
    "from sklearn.metrics import f1_score, roc_curve, auc, roc_auc_score, confusion_matrix\n",
    "from torch.nn.functional import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Transfomations import apply_translation\n",
    "from PCT_definition import sample_and_group, farthest_point_sample, index_points, square_distance, Local_op, SA_Layer, StackedAttention\n",
    "from Model_7_features import use_GPU, PairModel1, Branch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the seeds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=999\n",
    "os.environ[\"PL_GLOBAL_SEED\"] = str(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Case: Modification of random points with their mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import the proper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Mod_pointclouds import apply_obscure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:\\\\Users\\\\Alessandro\\\\Desktop\\\\Tesi\\\\PairModel\\\\test_subset_random.pkl', 'rb') as file:\n",
    "    test_randomized = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activate GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=use_GPU()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Test dataloader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader_basic = DataLoader(test_randomized, batch_size=16) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference cycle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_values = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7,0.8, 0.9]\n",
    "results = []\n",
    "\n",
    "# loop through percent_values\n",
    "for percent in percent_values:\n",
    "\n",
    "    # load pre-trained model each time\n",
    "    model = PairModel1().to(device)\n",
    "    model.double()\n",
    "    W_stored = torch.load(r'C:\\\\Users\\\\Alessandro\\\\Desktop\\\\Weights\\\\Main_epoch116.pt')\n",
    "    model.load_state_dict(W_stored)\n",
    "\n",
    "    # set up loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.00005, weight_decay=0.0001)\n",
    "    num_epochs = 1\n",
    "    best_val_accuracy = 0.0 \n",
    "\n",
    "    # set checkpoint directory\n",
    "    checkpoint_dir = r'C:\\\\Users\\\\Alessandro\\\\Desktop\\\\Tesi\\\\PairModel\\\\Check_points'\n",
    "\n",
    "    model.eval()  \n",
    "    progress_bar_val = tqdm(test_loader_basic, desc=f'Validation', leave=False)    \n",
    "    val_loss = 0.0\n",
    "    val_correct_predictions = 0\n",
    "    val_total_samples = 0\n",
    "    val_contrast = 0.0\n",
    "    y_true_val = []\n",
    "    y_pred_val = []\n",
    "    y_scores_val = [] \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_batch in progress_bar_val:\n",
    "            val_frags_a, val_frags_b, val_labels = val_batch\n",
    "             \n",
    "            # translations in the origin \n",
    "            val_frags_a = apply_translation(val_frags_a)\n",
    "            val_frags_b = apply_translation(val_frags_b)\n",
    " \n",
    "            # obscure random points\n",
    "            val_frags_b = apply_obscure(val_frags_b, percent)\n",
    "            val_frags_a = apply_obscure(val_frags_a, percent)\n",
    "\n",
    "            val_frags_a = val_frags_a.double().to(device)\n",
    "            val_frags_b = val_frags_b.double().to(device)\n",
    "\n",
    "            val_labels = val_labels.to(device)\n",
    "                \n",
    "            val_outputs = model(val_frags_a, val_frags_b)\n",
    "            \n",
    "            val_outputs_probs = softmax(val_outputs, dim=1)\n",
    "            val_loss += criterion(val_outputs, val_labels).item()\n",
    "          \n",
    "            _, val_predicted = torch.max(val_outputs.data, 1)\n",
    "            val_total_samples += val_labels.size(0)\n",
    "            val_correct_predictions += (val_predicted == val_labels).sum().item()\n",
    "            \n",
    "            y_true_val.extend(val_labels.cpu().numpy())\n",
    "            y_pred_val.extend(val_predicted.cpu().numpy())\n",
    "            y_scores_val.extend(val_outputs_probs.cpu().numpy()[:, 1])  \n",
    "    \n",
    "    # ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_true_val, y_scores_val)\n",
    "\n",
    "    # AUC\n",
    "    roc_auc = roc_auc_score(y_true_val, y_scores_val)\n",
    "\n",
    "    # F1-score, Accuracy, Val_loss\n",
    "    f1_val = f1_score(y_true_val, y_pred_val, average='weighted') \n",
    "    val_accuracy = val_correct_predictions / val_total_samples\n",
    "    val_loss /= len(test_loader_basic)\n",
    "\n",
    "    # store the results\n",
    "    results.append({\n",
    "        'percent': percent,\n",
    "        'val_accuracy': val_accuracy,\n",
    "        'f1_val': f1_val,\n",
    "        'roc_auc': roc_auc,\n",
    "        'val_loss': val_loss,\n",
    "        'conf_matrix': confusion_matrix(y_true_val, y_pred_val)\n",
    "    })\n",
    "    \n",
    "    # find the indices of the cases predicted well, predicted wrong, the cases predicted as zero and the cases as one\n",
    "    correctly_predicted_indices = np.where(np.array(y_true_val) == np.array(y_pred_val))[0]\n",
    "    incorrectly_predicted_indices = np.where(np.array(y_true_val) != np.array(y_pred_val))[0]\n",
    "    preds_0_indices = np.where(np.array(y_pred_val) == 0)[0]\n",
    "    preds_1_indices = np.where(np.array(y_pred_val) == 1)[0]\n",
    "\n",
    "    # create the directory if it doesn't exist\n",
    "    directory = 'first_case'\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    \n",
    "\n",
    "    # save all the indices associated with the various predictions:\n",
    "    with open(f'{directory}\\\\correctly_predicted_indices'+'_'+str(percent)+'.pkl', 'wb') as file:\n",
    "     pickle.dump(correctly_predicted_indices, file)\n",
    "\n",
    "    with open(f'{directory}\\\\incorrectly_predicted_indices'+'_'+str(percent)+'.pkl', 'wb') as file:\n",
    "     pickle.dump(incorrectly_predicted_indices, file)\n",
    "\n",
    "    with open(f'{directory}\\\\preds_0_indices'+'_'+str(percent)+'.pkl', 'wb') as file:\n",
    "     pickle.dump(preds_0_indices, file)\n",
    "\n",
    "    with open(f'{directory}\\\\preds_1_indices'+'_'+str(percent)+'.pkl', 'wb') as file:\n",
    "     pickle.dump(preds_1_indices, file)\n",
    "\n",
    "# store all the metrics     \n",
    "with open(f'{directory}\\\\results_tot.pkl', 'wb') as file:\n",
    "    pickle.dump(results, file)\n",
    "\n",
    "# print\n",
    "for result in results:\n",
    "    print(f\"Percent: {result['percent']}\")\n",
    "    print(\"Validation Accuracy:\", result['val_accuracy'])\n",
    "    print(\"Validation F1 Score:\", result['f1_val'])\n",
    "    print(\"Validation AUC:\", result['roc_auc'])\n",
    "    print(\"Validation Loss\", result['val_loss'])\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(result['conf_matrix'])\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Case: Modification of selected points with their mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import the proper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Mod_pointclouds import apply_obscure_with_mean_selected_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:\\\\Users\\\\Alessandro\\\\Desktop\\\\Tesi\\\\PairModel\\\\test_subset_random.pkl', 'rb') as file:\n",
    "    test_randomized = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activate GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=use_GPU()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Test dataloader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader_basic = DataLoader(test_randomized, batch_size=16) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference cycle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes_values = [0, 1, 2]\n",
    "fraction_values = [3, 2.5, 2, 1.5, 1.2]\n",
    "results = []\n",
    "\n",
    "# loop through axes and fractions\n",
    "for ax in tqdm(axes_values, desc='Axes'):\n",
    "    for fraction in tqdm(fraction_values, desc='Fractions', leave=False):\n",
    "        \n",
    "        # load pre-trained model each time\n",
    "        model = PairModel1().to(device)\n",
    "        model.double()\n",
    "        W_stored = torch.load(r'C:\\\\Users\\\\Alessandro\\\\Desktop\\\\Weights\\\\Main_epoch116.pt')\n",
    "        model.load_state_dict(W_stored)\n",
    "        \n",
    "        # set up loss and optimizer\n",
    "        criterion = nn.CrossEntropyLoss().to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.00005, weight_decay=0.0001)\n",
    "        num_epochs = 1\n",
    "        best_val_accuracy = 0.0\n",
    "        \n",
    "        # set checkpoint directory\n",
    "        checkpoint_dir = r'C:\\\\Users\\\\Alessandro\\\\Desktop\\\\Tesi\\\\PairModel\\\\Check_points'\n",
    "\n",
    "        model.eval()\n",
    "        progress_bar_val = tqdm(test_loader_basic, desc=f'Validation', leave=False)\n",
    "        val_loss = 0.0\n",
    "        val_correct_predictions = 0\n",
    "        val_total_samples = 0\n",
    "        val_contrast = 0.0\n",
    "        y_true_val = []\n",
    "        y_pred_val = []\n",
    "        y_scores_val = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for val_batch in progress_bar_val:\n",
    "                val_frags_a, val_frags_b, val_labels = val_batch\n",
    "                \n",
    "                # translations in the origin \n",
    "                val_frags_a = apply_translation(val_frags_a)\n",
    "                val_frags_b = apply_translation(val_frags_b)\n",
    "\n",
    "                # obscure selected points with their mean\n",
    "                val_frags_b = apply_obscure_with_mean_selected_points(val_frags_b, ax, frac=fraction)\n",
    "                val_frags_a = apply_obscure_with_mean_selected_points(val_frags_a, ax, frac=fraction)\n",
    "\n",
    "                val_frags_a = val_frags_a.double().to(device)\n",
    "                val_frags_b = val_frags_b.double().to(device)\n",
    "\n",
    "                val_labels = val_labels.to(device)\n",
    "\n",
    "                val_outputs = model(val_frags_a, val_frags_b)\n",
    "\n",
    "                val_outputs_probs = softmax(val_outputs, dim=1)\n",
    "                val_loss+= criterion(val_outputs, val_labels).item()\n",
    "\n",
    "                _, val_predicted = torch.max(val_outputs.data, 1)\n",
    "                val_total_samples += val_labels.size(0)\n",
    "                val_correct_predictions += (val_predicted == val_labels).sum().item()\n",
    "\n",
    "                y_true_val.extend(val_labels.cpu().numpy())\n",
    "                y_pred_val.extend(val_predicted.cpu().numpy())\n",
    "                y_scores_val.extend(val_outputs_probs.cpu().numpy()[:, 1])\n",
    "\n",
    "        # ROC curve\n",
    "        fpr, tpr, thresholds = roc_curve(y_true_val, y_scores_val)\n",
    "\n",
    "        # AUC\n",
    "        roc_auc = roc_auc_score(y_true_val, y_scores_val)\n",
    "\n",
    "        # F1-score, Accuracy, Val_loss\n",
    "        f1_val = f1_score(y_true_val, y_pred_val, average='weighted')\n",
    "        val_accuracy = val_correct_predictions / val_total_samples\n",
    "        val_loss /= len(test_loader_basic)\n",
    "\n",
    "        # store the results \n",
    "        results.append({\n",
    "            'ax': ax,\n",
    "            'fraction': fraction,\n",
    "            'val_accuracy': val_accuracy,\n",
    "            'f1_val': f1_val,\n",
    "            'roc_auc': roc_auc,\n",
    "            'val_loss': val_loss,\n",
    "            'conf_matrix': confusion_matrix(y_true_val, y_pred_val)\n",
    "        })\n",
    "        \n",
    "        # find the indices of the cases predicted well, predicted wrong, the cases predicted as zero and the cases as one\n",
    "        correctly_predicted_indices = np.where(np.array(y_true_val) == np.array(y_pred_val))[0]\n",
    "        incorrectly_predicted_indices = np.where(np.array(y_true_val) != np.array(y_pred_val))[0]\n",
    "        preds_0_indices = np.where(np.array(y_pred_val) == 0)[0]\n",
    "        preds_1_indices = np.where(np.array(y_pred_val) == 1)[0]\n",
    "        \n",
    "        # create the directory if it doesn't exist\n",
    "        directory = 'second_case_mean'\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "        # save all the indices associated with the various predictions:\n",
    "        with open(f'{directory}\\\\correctly_predicted_indices{ax}_{fraction}.pkl', 'wb') as file:\n",
    "            pickle.dump(correctly_predicted_indices, file)\n",
    "\n",
    "        with open(f'{directory}\\\\incorrectly_predicted_indices{ax}_{fraction}.pkl', 'wb') as file:\n",
    "            pickle.dump(incorrectly_predicted_indices, file)\n",
    "\n",
    "        with open(f'{directory}\\\\preds_0_indices{ax}_{fraction}.pkl', 'wb') as file:\n",
    "            pickle.dump(preds_0_indices, file)\n",
    "\n",
    "        with open(f'{directory}\\\\preds_1_indices{ax}_{fraction}.pkl', 'wb') as file:\n",
    "            pickle.dump(preds_1_indices, file)\n",
    "\n",
    "\n",
    "# store all the metrics   \n",
    "with open(f'{directory}\\\\results_tot.pkl', 'wb') as file:\n",
    "    pickle.dump(results, file)\n",
    "\n",
    "# print\n",
    "for result in results:\n",
    "    print(\"Axis:\", result['ax'])\n",
    "    print(\"Fraction:\", result['fraction'])\n",
    "    print(\"Validation Accuracy:\", result['val_accuracy'])\n",
    "    print(\"Validation F1 Score:\", result['f1_val'])\n",
    "    print(\"Validation AUC:\", result['roc_auc'])\n",
    "    print(\"Validation Loss\", result['val_loss'])\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(result['conf_matrix'])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third Case: Modification of selected points with coordinates from existing points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import the proper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Mod_pointclouds import apply_obscure_selected_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:\\\\Users\\\\Alessandro\\\\Desktop\\\\Tesi\\\\PairModel\\\\test_subset_random.pkl', 'rb') as file:\n",
    "    test_randomized = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activate GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=use_GPU()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Test dataloader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader_basic = DataLoader(test_randomized, batch_size=16) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference cycle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes_values = [0, 1, 2]\n",
    "fraction_values = [3, 2.5, 2, 1.5, 1.2]\n",
    "results = []\n",
    "\n",
    "# loop through axes and fractions\n",
    "for ax in tqdm(axes_values, desc='Axes'):\n",
    "    for fraction in tqdm(fraction_values, desc='Fractions', leave=False):\n",
    "        \n",
    "        # load pre-trained model each time\n",
    "        model = PairModel1().to(device)\n",
    "        model.double()\n",
    "        W_stored = torch.load(r'C:\\\\Users\\\\Alessandro\\\\Desktop\\\\Weights\\\\Main_epoch116.pt')\n",
    "        model.load_state_dict(W_stored)\n",
    "        \n",
    "        # set up loss and optimizer\n",
    "        criterion = nn.CrossEntropyLoss().to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.00005, weight_decay=0.0001)\n",
    "        num_epochs = 1\n",
    "        best_val_accuracy = 0.0\n",
    "        \n",
    "        # set checkpoint directory\n",
    "        checkpoint_dir = r'C:\\\\Users\\\\Alessandro\\\\Desktop\\\\Tesi\\\\PairModel\\\\Check_points'\n",
    "\n",
    "        model.eval()\n",
    "        progress_bar_val = tqdm(test_loader_basic, desc=f'Validation', leave=False)\n",
    "        val_loss = 0.0\n",
    "        val_correct_predictions = 0\n",
    "        val_total_samples = 0\n",
    "        val_contrast = 0.0\n",
    "        y_true_val = []\n",
    "        y_pred_val = []\n",
    "        y_scores_val = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for val_batch in progress_bar_val:\n",
    "                val_frags_a, val_frags_b, val_labels = val_batch\n",
    "                \n",
    "                # translations in the origin \n",
    "                val_frags_a = apply_translation(val_frags_a)\n",
    "                val_frags_b = apply_translation(val_frags_b)\n",
    "\n",
    "                # obscure selected points with coordinates from existing points\n",
    "                val_frags_b = apply_obscure_selected_points(val_frags_b, ax, frac=fraction)\n",
    "                val_frags_a = apply_obscure_selected_points(val_frags_a, ax, frac=fraction)\n",
    "\n",
    "                val_frags_a = val_frags_a.double().to(device)\n",
    "                val_frags_b = val_frags_b.double().to(device)\n",
    "\n",
    "                val_labels = val_labels.to(device)\n",
    "\n",
    "                val_outputs = model(val_frags_a, val_frags_b)\n",
    "\n",
    "                val_outputs_probs = softmax(val_outputs, dim=1)\n",
    "                val_loss+= criterion(val_outputs, val_labels).item()\n",
    "\n",
    "                _, val_predicted = torch.max(val_outputs.data, 1)\n",
    "                val_total_samples += val_labels.size(0)\n",
    "                val_correct_predictions += (val_predicted == val_labels).sum().item()\n",
    "\n",
    "                y_true_val.extend(val_labels.cpu().numpy())\n",
    "                y_pred_val.extend(val_predicted.cpu().numpy())\n",
    "                y_scores_val.extend(val_outputs_probs.cpu().numpy()[:, 1])\n",
    "\n",
    "        # ROC curve\n",
    "        fpr, tpr, thresholds = roc_curve(y_true_val, y_scores_val)\n",
    "\n",
    "        # AUC\n",
    "        roc_auc = roc_auc_score(y_true_val, y_scores_val)\n",
    "\n",
    "        # F1-score, Accuracy, Val_loss\n",
    "        f1_val = f1_score(y_true_val, y_pred_val, average='weighted')\n",
    "        val_accuracy = val_correct_predictions / val_total_samples\n",
    "        val_loss /= len(test_loader_basic)\n",
    "\n",
    "        # store the results \n",
    "        results.append({\n",
    "            'ax': ax,\n",
    "            'fraction': fraction,\n",
    "            'val_accuracy': val_accuracy,\n",
    "            'f1_val': f1_val,\n",
    "            'roc_auc': roc_auc,\n",
    "            'val_loss': val_loss,\n",
    "            'conf_matrix': confusion_matrix(y_true_val, y_pred_val)\n",
    "        })\n",
    "        \n",
    "        # find the indices of the cases predicted well, predicted wrong, the cases predicted as zero and the cases as one\n",
    "        correctly_predicted_indices = np.where(np.array(y_true_val) == np.array(y_pred_val))[0]\n",
    "        incorrectly_predicted_indices = np.where(np.array(y_true_val) != np.array(y_pred_val))[0]\n",
    "        preds_0_indices = np.where(np.array(y_pred_val) == 0)[0]\n",
    "        preds_1_indices = np.where(np.array(y_pred_val) == 1)[0]\n",
    "        \n",
    "        # create the directory if it doesn't exist\n",
    "        directory = 'third_case_existing_points'\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "        # save all the indices associated with the various predictions:\n",
    "        with open(f'{directory}\\\\correctly_predicted_indices{ax}_{fraction}.pkl', 'wb') as file:\n",
    "            pickle.dump(correctly_predicted_indices, file)\n",
    "\n",
    "        with open(f'{directory}\\\\incorrectly_predicted_indices{ax}_{fraction}.pkl', 'wb') as file:\n",
    "            pickle.dump(incorrectly_predicted_indices, file)\n",
    "\n",
    "        with open(f'{directory}\\\\preds_0_indices{ax}_{fraction}.pkl', 'wb') as file:\n",
    "            pickle.dump(preds_0_indices, file)\n",
    "\n",
    "        with open(f'{directory}\\\\preds_1_indices{ax}_{fraction}.pkl', 'wb') as file:\n",
    "            pickle.dump(preds_1_indices, file)\n",
    "\n",
    "\n",
    "# store all the metrics   \n",
    "with open(f'{directory}\\\\results_tot.pkl', 'wb') as file:\n",
    "    pickle.dump(results, file)\n",
    "\n",
    "# print\n",
    "for result in results:\n",
    "    print(\"Axis:\", result['ax'])\n",
    "    print(\"Fraction:\", result['fraction'])\n",
    "    print(\"Validation Accuracy:\", result['val_accuracy'])\n",
    "    print(\"Validation F1 Score:\", result['f1_val'])\n",
    "    print(\"Validation AUC:\", result['roc_auc'])\n",
    "    print(\"Validation Loss\", result['val_loss'])\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(result['conf_matrix'])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourth case: Modification of selected points by adding noise (generating new points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import the proper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Mod_pointclouds import apply_generate_selected_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:\\\\Users\\\\Alessandro\\\\Desktop\\\\Tesi\\\\PairModel\\\\test_subset_random.pkl', 'rb') as file:\n",
    "    test_randomized = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activate GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=use_GPU()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Test dataloader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader_basic = DataLoader(test_randomized, batch_size=16) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference cycle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes_values = [0, 1, 2]\n",
    "fraction_values = [3, 2.5, 2, 1.5, 1.2]\n",
    "results = []\n",
    "\n",
    "# loop through axes and fractions\n",
    "for ax in tqdm(axes_values, desc='Axes'):\n",
    "    for fraction in tqdm(fraction_values, desc='Fractions', leave=False):\n",
    "        \n",
    "        # load pre-trained model each time\n",
    "        model = PairModel1().to(device)\n",
    "        model.double()\n",
    "        W_stored = torch.load(r'C:\\\\Users\\\\Alessandro\\\\Desktop\\\\Weights\\\\Main_epoch116.pt')\n",
    "        model.load_state_dict(W_stored)\n",
    "        \n",
    "        # set up loss and optimizer\n",
    "        criterion = nn.CrossEntropyLoss().to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.00005, weight_decay=0.0001)\n",
    "        num_epochs = 1\n",
    "        best_val_accuracy = 0.0\n",
    "        \n",
    "        # set checkpoint directory\n",
    "        checkpoint_dir = r'C:\\\\Users\\\\Alessandro\\\\Desktop\\\\Tesi\\\\PairModel\\\\Check_points'\n",
    "\n",
    "        model.eval()\n",
    "        progress_bar_val = tqdm(test_loader_basic, desc=f'Validation', leave=False)\n",
    "        val_loss = 0.0\n",
    "        val_correct_predictions = 0\n",
    "        val_total_samples = 0\n",
    "        val_contrast = 0.0\n",
    "        y_true_val = []\n",
    "        y_pred_val = []\n",
    "        y_scores_val = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for val_batch in progress_bar_val:\n",
    "                val_frags_a, val_frags_b, val_labels = val_batch\n",
    "                \n",
    "                # translations in the origin \n",
    "                val_frags_a = apply_translation(val_frags_a)\n",
    "                val_frags_b = apply_translation(val_frags_b)\n",
    "\n",
    "                # modify selected points by adding noise to coordinates\n",
    "                val_frags_b = apply_generate_selected_points(val_frags_b, ax, frac=fraction)\n",
    "                val_frags_a = apply_generate_selected_points(val_frags_a, ax, frac=fraction)\n",
    "\n",
    "                val_frags_a = val_frags_a.double().to(device)\n",
    "                val_frags_b = val_frags_b.double().to(device)\n",
    "\n",
    "                val_labels = val_labels.to(device)\n",
    "\n",
    "                val_outputs = model(val_frags_a, val_frags_b)\n",
    "\n",
    "                val_outputs_probs = softmax(val_outputs, dim=1)\n",
    "                val_loss+= criterion(val_outputs, val_labels).item()\n",
    "\n",
    "                _, val_predicted = torch.max(val_outputs.data, 1)\n",
    "                val_total_samples += val_labels.size(0)\n",
    "                val_correct_predictions += (val_predicted == val_labels).sum().item()\n",
    "\n",
    "                y_true_val.extend(val_labels.cpu().numpy())\n",
    "                y_pred_val.extend(val_predicted.cpu().numpy())\n",
    "                y_scores_val.extend(val_outputs_probs.cpu().numpy()[:, 1])\n",
    "\n",
    "        # ROC curve\n",
    "        fpr, tpr, thresholds = roc_curve(y_true_val, y_scores_val)\n",
    "\n",
    "        # AUC\n",
    "        roc_auc = roc_auc_score(y_true_val, y_scores_val)\n",
    "\n",
    "        # F1-score, Accuracy, Val_loss\n",
    "        f1_val = f1_score(y_true_val, y_pred_val, average='weighted')\n",
    "        val_accuracy = val_correct_predictions / val_total_samples\n",
    "        val_loss /= len(test_loader_basic)\n",
    "\n",
    "        # store the results \n",
    "        results.append({\n",
    "            'ax': ax,\n",
    "            'fraction': fraction,\n",
    "            'val_accuracy': val_accuracy,\n",
    "            'f1_val': f1_val,\n",
    "            'roc_auc': roc_auc,\n",
    "            'val_loss': val_loss,\n",
    "            'conf_matrix': confusion_matrix(y_true_val, y_pred_val)\n",
    "        })\n",
    "        \n",
    "        # find the indices of the cases predicted well, predicted wrong, the cases predicted as zero and the cases as one\n",
    "        correctly_predicted_indices = np.where(np.array(y_true_val) == np.array(y_pred_val))[0]\n",
    "        incorrectly_predicted_indices = np.where(np.array(y_true_val) != np.array(y_pred_val))[0]\n",
    "        preds_0_indices = np.where(np.array(y_pred_val) == 0)[0]\n",
    "        preds_1_indices = np.where(np.array(y_pred_val) == 1)[0]\n",
    "        \n",
    "        # create the directory if it doesn't exist\n",
    "        directory = 'fourth_case'\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "        # save all the indices associated with the various predictions:\n",
    "        with open(f'{directory}\\\\correctly_predicted_indices{ax}_{fraction}.pkl', 'wb') as file:\n",
    "            pickle.dump(correctly_predicted_indices, file)\n",
    "\n",
    "        with open(f'{directory}\\\\incorrectly_predicted_indices{ax}_{fraction}.pkl', 'wb') as file:\n",
    "            pickle.dump(incorrectly_predicted_indices, file)\n",
    "\n",
    "        with open(f'{directory}\\\\preds_0_indices{ax}_{fraction}.pkl', 'wb') as file:\n",
    "            pickle.dump(preds_0_indices, file)\n",
    "\n",
    "        with open(f'{directory}\\\\preds_1_indices{ax}_{fraction}.pkl', 'wb') as file:\n",
    "            pickle.dump(preds_1_indices, file)\n",
    "\n",
    "\n",
    "# store all the metrics   \n",
    "with open(f'{directory}\\\\results_tot.pkl', 'wb') as file:\n",
    "    pickle.dump(results, file)\n",
    "\n",
    "# print\n",
    "for result in results:\n",
    "    print(\"Axis:\", result['ax'])\n",
    "    print(\"Fraction:\", result['fraction'])\n",
    "    print(\"Validation Accuracy:\", result['val_accuracy'])\n",
    "    print(\"Validation F1 Score:\", result['f1_val'])\n",
    "    print(\"Validation AUC:\", result['roc_auc'])\n",
    "    print(\"Validation Loss\", result['val_loss'])\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(result['conf_matrix'])\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
