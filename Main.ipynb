{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages e define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import random\n",
    "import pickle\n",
    "import datetime\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "from scipy.stats import special_ortho_group\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import torch.nn.functional as F\n",
    "#from pytorch_metric_learning import miners, losses\n",
    "import wandb\n",
    "import itertools\n",
    "from sklearn.metrics import f1_score, roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wandb api key: 96753ce682b21ba1903b8bf57d7786ba04926b15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fix the seed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=999\n",
    "os.environ[\"PL_GLOBAL_SEED\"] = str(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateCouples(pt):\n",
    "    \n",
    "    \"\"\" This function, modifies the shape of the tensor to fit the model \n",
    "\n",
    "    \"\"\"\n",
    "    clusters= pt.shape[0]\n",
    "    couples = []\n",
    "    # for each subcluster\n",
    "    for i in tqdm(range(0,clusters)):\n",
    "        \n",
    "        # discover the number of fragments\n",
    "        n_frags = pt[i][0].shape[0]\n",
    "\n",
    "        # exract the adj matrix\n",
    "        matr= pt[i][0]\n",
    "\n",
    "        # exract the cluster of fragments\n",
    "        data = pt[i][1]\n",
    "        \n",
    "        for j in range(0,n_frags -1):\n",
    "            \n",
    "            init = j+1\n",
    "            for k in range(init,n_frags): \n",
    "\n",
    "             couples.append([data[j], data[k], matr[j][k]])\n",
    "    return couples \n",
    "\n",
    "def CreateCouples_cluster(pt):\n",
    "    \"\"\" This function, modifies the shape of the tensor to fit the model \"\"\"\n",
    "    clusters = pt.shape[0]\n",
    "    cluster_list = []\n",
    "\n",
    "    for i in tqdm(range(clusters)):\n",
    "        n_frags = pt[i][0].shape[0]\n",
    "        matr = pt[i][0]\n",
    "        data = pt[i][1]\n",
    "        cluster_couples = []\n",
    "\n",
    "        for j in range(n_frags - 1):\n",
    "            init = j + 1\n",
    "            for k in range(init, n_frags):\n",
    "                cluster_couples.append([data[j], data[k], matr[j][k]])\n",
    "\n",
    "        cluster_list.append(cluster_couples)\n",
    "\n",
    "    return cluster_list\n",
    "def center_in_origin(frag):\n",
    "    min_vals, _ = torch.min(frag[:, 0:3], axis=0)\n",
    "    max_vals, _ = torch.max(frag[:, 0:3], axis=0)\n",
    "    frag[:, 0:3] = (frag[:, 0:3] - min_vals) / (max_vals - min_vals)\n",
    "    \n",
    "    return frag\n",
    "    \n",
    "def normalize(batch):\n",
    "    out=[]\n",
    "    for element in batch:\n",
    "        out.append(center_in_origin(element))\n",
    "    out_tensor = torch.stack(out)    \n",
    "    return out_tensor  \n",
    "\n",
    "\n",
    "\n",
    "def use_GPU():\n",
    "    \"\"\" This function activates the gpu \n",
    "    \"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(torch.cuda.get_device_name(0), \"is available and being used\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"GPU is not available, using CPU instead\") \n",
    "    return device  \n",
    "\n",
    "\n",
    "\n",
    "def translate_to_origin(frag):\n",
    "    \"\"\" This function translate each fragment in the origin\n",
    "    \"\"\"\n",
    "    frag[:,:3] -= torch.mean(frag[:,:3]) \n",
    "    return frag\n",
    "\n",
    "def apply_translation(batch):\n",
    "    \"\"\" This function apply translate_to_origin() to each fragment in the batch\n",
    "    \"\"\"\n",
    "    out=[]\n",
    "    for element in batch:\n",
    "        out.append(translate_to_origin(element))\n",
    "    out_tensor = torch.stack(out)    \n",
    "    return out_tensor\n",
    "\n",
    "\n",
    "def random_rotation(frag):\n",
    "\n",
    "    randrot = (torch.rand(3)*360).tolist()\n",
    "    r = R.from_euler('zyx', randrot, degrees=True)\n",
    "    frag[:,:3] = torch.from_numpy(r.apply(frag[:,:3]))\n",
    "    frag[:,3:6] = torch.from_numpy(r.apply(frag[:,3:6]))\n",
    "    return frag\n",
    "\n",
    "def apply_randomrotations(batch):\n",
    "    \"\"\" This function apply random_rotation() to each fragment in the batch\n",
    "    \"\"\"\n",
    "    out=[]\n",
    "    for element in batch:\n",
    "        out.append(random_rotation(element))\n",
    "    out_tensor = torch.stack(out)    \n",
    "    return out_tensor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    def __init__(self, m=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.m = m\n",
    "\n",
    "    def forward(self, y1, y2, d):\n",
    "        euc_dist = torch.nn.functional.pairwise_distance(y1, y2)\n",
    "\n",
    "        if d.dim() == 0:  # Se d è uno scalare\n",
    "            if d == 0:\n",
    "                return torch.mean(torch.pow(euc_dist, 2))  # Distanza quadratica\n",
    "            else:  # d == 1\n",
    "                delta = self.m - euc_dist\n",
    "                delta = torch.clamp(delta, min=0.0, max=None)\n",
    "                return torch.mean(torch.pow(delta, 2))\n",
    "        else:  # Se d è un tensore di valori 0 e 1\n",
    "            is_same = d == 0\n",
    "            is_diff = d == 1\n",
    "\n",
    "            loss_same = torch.pow(euc_dist[is_same], 2).mean() if torch.any(is_same) else torch.tensor(0.0).to(euc_dist.device)\n",
    "            loss_diff = torch.pow(torch.clamp(self.m - euc_dist[is_diff], min=0.0), 2).mean() if torch.any(is_diff) else torch.tensor(0.0).to(euc_dist.device)\n",
    "\n",
    "            return (loss_same + loss_diff) / (1.0 + torch.any(is_same).float() + torch.any(is_diff).float())\n",
    "        \n",
    "def divide_macro_element(val_couples_c, macro_index):\n",
    "    macro = val_couples_c[macro_index]\n",
    "    #random.shuffle(macro)\n",
    "    nuova_lista=[]\n",
    "    primi = []\n",
    "    secondi = []\n",
    "    terzi = []\n",
    "    \n",
    "    for tripletta in macro:\n",
    "        primi.append(tripletta[0])\n",
    "        secondi.append(tripletta[1])\n",
    "        terzi.append(tripletta[2])\n",
    "    \n",
    "    primi_divisi = [[x] for x in primi]\n",
    "    secondi_divisi = [[x] for x in secondi]\n",
    "    terzi_divisi = [[x] for x in terzi]\n",
    "    \n",
    "    nuova_lista.append([primi_divisi, secondi_divisi, terzi_divisi])\n",
    "    \n",
    "    primi = []\n",
    "    secondi = []\n",
    "    terzi = []\n",
    "\n",
    "    for macro in nuova_lista:\n",
    "        primi.append(macro[0])\n",
    "        secondi.append(macro[1])\n",
    "        terzi.append(macro[2])\n",
    "\n",
    "    primi = list(itertools.chain.from_iterable(primi))\n",
    "    secondi = list(itertools.chain.from_iterable(secondi))\n",
    "    terzi = list(itertools.chain.from_iterable(terzi))\n",
    "    val_divisione_nuova = []\n",
    "    for i in range(len(primi)):\n",
    "        val_divisione_nuova.append([primi[i], secondi[i], terzi[i]])\n",
    "    \n",
    "    return val_divisione_nuova        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/qq456cvb/Point-Transformers\n",
    "\n",
    "def square_distance(src, dst):\n",
    "    \"\"\"\n",
    "    Calculate Euclid distance between each two points.\n",
    "    src^T * dst = xn * xm + yn * ym + zn * zm；\n",
    "    sum(src^2, dim=-1) = xn*xn + yn*yn + zn*zn;\n",
    "    sum(dst^2, dim=-1) = xm*xm + ym*ym + zm*zm;\n",
    "    dist = (xn - xm)^2 + (yn - ym)^2 + (zn - zm)^2\n",
    "         = sum(src**2,dim=-1)+sum(dst**2,dim=-1)-2*src^T*dst\n",
    "    Input:\n",
    "        src: source points, [B, N, C]\n",
    "        dst: target points, [B, M, C]\n",
    "    Output:\n",
    "        dist: per-point square distance, [B, N, M]\n",
    "    \"\"\"\n",
    "    return torch.sum((src[:, :, None] - dst[:, None]) ** 2, dim=-1)\n",
    "\n",
    "def index_points(points, idx):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        points: input points data, [B, N, C]\n",
    "        idx: sample index data, [B, S, [K]]\n",
    "    Return:\n",
    "        new_points:, indexed points data, [B, S, [K], C]\n",
    "    \"\"\"\n",
    "    raw_size = idx.size()\n",
    "    idx = idx.reshape(raw_size[0], -1)\n",
    "    res = torch.gather(points, 1, idx[..., None].expand(-1, -1, points.size(-1)))\n",
    "    return res.reshape(*raw_size, -1)\n",
    "\n",
    "\n",
    "def farthest_point_sample(xyz, npoint):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        xyz: pointcloud data, [B, N, 3]\n",
    "        npoint: number of samples\n",
    "    Return:\n",
    "        centroids: sampled pointcloud index, [B, npoint]\n",
    "    \"\"\"\n",
    "    device = xyz.device\n",
    "    B, N, C = xyz.shape\n",
    "    centroids = torch.zeros(B, npoint, dtype=torch.long).to(device)\n",
    "    distance = torch.ones(B, N).to(device) * 1e10\n",
    "    farthest = torch.randint(0, N, (B,), dtype=torch.long).to(device)\n",
    "    batch_indices = torch.arange(B, dtype=torch.long).to(device)\n",
    "    for i in range(npoint):\n",
    "        centroids[:, i] = farthest\n",
    "        centroid = xyz[batch_indices, farthest, :].view(B, 1, 3)\n",
    "        dist = torch.sum((xyz - centroid) ** 2, -1)\n",
    "        distance = torch.min(distance, dist)\n",
    "        farthest = torch.max(distance, -1)[1]\n",
    "    return centroids\n",
    "\n",
    "def sample_and_group(npoint, nsample, xyz, points):\n",
    "    B, N, C = xyz.shape\n",
    "    S = npoint \n",
    "    \n",
    "    fps_idx = farthest_point_sample(xyz, npoint) # [B, npoint]\n",
    "\n",
    "    new_xyz = index_points(xyz, fps_idx) \n",
    "    new_points = index_points(points, fps_idx)\n",
    "\n",
    "    dists = square_distance(new_xyz, xyz)  # B x npoint x N\n",
    "    idx = dists.argsort()[:, :, :nsample]  # B x npoint x K\n",
    "\n",
    "    grouped_points = index_points(points, idx)\n",
    "    grouped_points_norm = grouped_points - new_points.view(B, S, 1, -1)\n",
    "    new_points = torch.cat([grouped_points_norm, new_points.view(B, S, 1, -1).repeat(1, 1, nsample, 1)], dim=-1)\n",
    "    return new_xyz, new_points\n",
    "\n",
    "\n",
    "class Local_op(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, n, s, d = x.size()  # torch.Size([32, 512, 32, 6]) \n",
    "        x = x.permute(0, 1, 3, 2)\n",
    "        x = x.reshape(-1, d, s)\n",
    "        batch_size, _, N = x.size()\n",
    "        x = self.relu(self.bn1(self.conv1(x))) # B, D, N\n",
    "        x = self.relu(self.bn2(self.conv2(x))) # B, D, N\n",
    "        x = torch.max(x, 2)[0]\n",
    "        x = x.view(batch_size, -1)\n",
    "        x = x.reshape(b, n, -1).permute(0, 2, 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SA_Layer(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.q_conv = nn.Conv1d(channels, channels // 4, 1, bias=False)\n",
    "        self.k_conv = nn.Conv1d(channels, channels // 4, 1, bias=False)\n",
    "        self.q_conv.weight = self.k_conv.weight \n",
    "        self.v_conv = nn.Conv1d(channels, channels, 1)\n",
    "        self.trans_conv = nn.Conv1d(channels, channels, 1)\n",
    "        self.after_norm = nn.BatchNorm1d(channels)\n",
    "        self.act = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_q = self.q_conv(x).permute(0, 2, 1) # b, n, c \n",
    "        x_k = self.k_conv(x)# b, c, n        \n",
    "        x_v = self.v_conv(x)\n",
    "        energy = x_q @ x_k # b, n, n \n",
    "        attention = self.softmax(energy)\n",
    "        attention = attention / (1e-9 + attention.sum(dim=1, keepdims=True))\n",
    "        x_r = x_v @ attention # b, c, n \n",
    "        x_r = self.act(self.after_norm(self.trans_conv(x - x_r)))\n",
    "        x = x + x_r\n",
    "        return x\n",
    "    \n",
    "\n",
    "class StackedAttention(nn.Module):\n",
    "    def __init__(self, channels=256):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(channels, channels, kernel_size=1, bias=False)\n",
    "        self.conv2 = nn.Conv1d(channels, channels, kernel_size=1, bias=False)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(channels)\n",
    "        self.bn2 = nn.BatchNorm1d(channels)\n",
    "\n",
    "        self.sa1 = SA_Layer(channels)\n",
    "        self.sa2 = SA_Layer(channels)\n",
    "        self.sa3 = SA_Layer(channels)\n",
    "        self.sa4 = SA_Layer(channels)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # \n",
    "        # b, 3, npoint, nsample  \n",
    "        # conv2d 3 -> 128 channels 1, 1\n",
    "        # b * npoint, c, nsample \n",
    "        # permute reshape\n",
    "        batch_size, _, N = x.size()\n",
    "\n",
    "        x = self.relu(self.bn1(self.conv1(x))) # B, D, N\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "\n",
    "        x1 = self.sa1(x)\n",
    "        x2 = self.sa2(x1)\n",
    "        x3 = self.sa3(x2)\n",
    "        x4 = self.sa4(x3)\n",
    "        \n",
    "        x = torch.cat((x1, x2, x3, x4), dim=1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Branch(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        d_points = 7 # we have 7 features for each point\n",
    "        self.conv1 = nn.Conv1d(d_points, 64, kernel_size=1, bias=False)\n",
    "        self.conv2 = nn.Conv1d(64, 64, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.gather_local_0 = Local_op(in_channels=128, out_channels=128)\n",
    "        self.gather_local_1 = Local_op(in_channels=256, out_channels=256)\n",
    "        self.pt_last = StackedAttention()\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv_fuse = nn.Sequential(nn.Conv1d(1280, 1024, kernel_size=1, bias=False),\n",
    "                                   nn.BatchNorm1d(1024),\n",
    "                                   nn.LeakyReLU(negative_slope=0.2))\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        xyz = x[..., :3]\n",
    "        x = x.permute(0, 2, 1)\n",
    "        batch_size, _, _ = x.size()\n",
    "        x= x.double()\n",
    "        x = self.relu(self.bn1(self.conv1(x))) # B, D, N\n",
    "        x = self.relu(self.bn2(self.conv2(x))) # B, D, N\n",
    "        x = x.permute(0, 2, 1)\n",
    "        new_xyz, new_feature = sample_and_group(npoint=512, nsample=32, xyz=xyz, points=x)         \n",
    "        feature_0 = self.gather_local_0(new_feature)\n",
    "        feature = feature_0.permute(0, 2, 1)\n",
    "        new_xyz, new_feature = sample_and_group(npoint=256, nsample=32, xyz=new_xyz, points=feature) \n",
    "        feature_1 = self.gather_local_1(new_feature)\n",
    "        \n",
    "        x = self.pt_last(feature_1)\n",
    "        x = torch.cat([x, feature_1], dim=1)\n",
    "        x = self.conv_fuse(x)\n",
    "        x = torch.max(x, 2)[0] # Returns the maximum value of all elements in the input tensor. (2 elementes for each vector)\n",
    "        x = x.view(batch_size, -1) # Returns a new tensor with the same data as the self tensor but of a different shape.\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "class PairModel1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        output_channels = 2 # it's a binary classification\n",
    "\n",
    "        self.branch1 = Branch()\n",
    "        self.branch2 = Branch()\n",
    "        self.dp1 = nn.Dropout(p=0.5)\n",
    "        self.relu = nn.ReLU()\n",
    "            \n",
    "        # classificator\n",
    "        self.linear1 = nn.Linear(2048, 512, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.dp2 = nn.Dropout(p=0.5)\n",
    "        self.linear2 = nn.Linear(512, 256)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.dp3 = nn.Dropout(p=0.5)\n",
    "        self.linear3 = nn.Linear(256, output_channels)\n",
    "        \n",
    "    def forward(self, batch_1, batch_2):\n",
    "        #for param in self.branch1.parameters():\n",
    "           #param.requires_grad = False\n",
    "        #for param in self.branch2.parameters():\n",
    "           #param.requires_grad = False\n",
    "        x_1 = self.branch1(batch_1)\n",
    "        x_2 = self.branch2(batch_2)\n",
    "        #print(x_1.shape)\n",
    "        #print(x_2.shape)\n",
    "        x_mult = x_1 * x_2 # let's sum the output of the two branches \n",
    "        x_sum = x_1 + x_2\n",
    "        x = torch.cat((x_mult, x_sum), dim=1) \n",
    "        #x = self.dp1(x)\n",
    "\n",
    "        # classificator\n",
    "        x = self.relu(self.bn1(self.linear1(x)))\n",
    "        x = self.dp2(x)\n",
    "        x = self.relu(self.bn2(self.linear2(x)))\n",
    "        x = self.dp3(x)\n",
    "        x = self.linear3(x)\n",
    "        #x = F.softmax(x, dim=1)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.load(\"C:\\\\Users\\\\Alessandro\\\\Desktop\\\\Tesi\\\\pair_dataset\\\\dataset_1024_AB\\\\train_pair_dataset_REG.pt\")\n",
    "val = torch.load(\"C:\\\\Users\\\\Alessandro\\\\Desktop\\\\Tesi\\\\pair_dataset\\\\dataset_1024_AB\\\\val_pair_dataset_REG.pt\")\n",
    "test = torch.load(\"C:\\\\Users\\\\Alessandro\\\\Desktop\\\\Tesi\\\\pair_dataset\\\\dataset_1024_AB\\\\test_pair_dataset_REG.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1526 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1526/1526 [00:01<00:00, 1021.78it/s]\n",
      "100%|██████████| 327/327 [00:00<00:00, 2130.11it/s]\n",
      "100%|██████████| 327/327 [00:00<00:00, 2369.13it/s]\n"
     ]
    }
   ],
   "source": [
    "# Change the shape of the data\n",
    "train_couples = CreateCouples(train)\n",
    "val_couples = CreateCouples(val)\n",
    "test_couples = CreateCouples(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 1713243\n",
      "Val 372814\n",
      "Test 348337\n"
     ]
    }
   ],
   "source": [
    "print(\"Train\",len(train_couples))\n",
    "print(\"Val\",len(val_couples))\n",
    "print(\"Test\",len(test_couples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_couples_0 = [item for item in train_couples if item[2] == 0]\n",
    "train_couples_1 = [item for item in train_couples if item[2] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Coupels 245362\n",
      "Negative Coupels 1467881\n"
     ]
    }
   ],
   "source": [
    "print(\"Positive Coupels\",len(train_couples_1))\n",
    "print(\"Negative Coupels\",len(train_couples_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_1 = [[item[0], item[1],item[2]] for item in val_couples if item[2] == 1]\n",
    "val_0 = [[item[0], item[1],item[2]] for item in val_couples if item[2] == 0]\n",
    "val_0_s = val_0[0:3000]\n",
    "val_1_s = val_1[0:3000]\n",
    "\n",
    "val_list = val_1_s + val_0_s\n",
    "random.shuffle(val_list) \n",
    "val_loader_basic = DataLoader(val_list, batch_size=16)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 4080 is available and being used\n"
     ]
    }
   ],
   "source": [
    "device=use_GPU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PairModel1(\n",
       "  (branch1): Branch(\n",
       "    (conv1): Conv1d(7, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (conv2): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (gather_local_0): Local_op(\n",
       "      (conv1): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (gather_local_1): Local_op(\n",
       "      (conv1): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (pt_last): StackedAttention(\n",
       "      (conv1): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (sa1): SA_Layer(\n",
       "        (q_conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (k_conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (v_conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "        (trans_conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "        (after_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU()\n",
       "        (softmax): Softmax(dim=-1)\n",
       "      )\n",
       "      (sa2): SA_Layer(\n",
       "        (q_conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (k_conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (v_conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "        (trans_conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "        (after_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU()\n",
       "        (softmax): Softmax(dim=-1)\n",
       "      )\n",
       "      (sa3): SA_Layer(\n",
       "        (q_conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (k_conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (v_conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "        (trans_conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "        (after_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU()\n",
       "        (softmax): Softmax(dim=-1)\n",
       "      )\n",
       "      (sa4): SA_Layer(\n",
       "        (q_conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (k_conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (v_conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "        (trans_conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "        (after_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU()\n",
       "        (softmax): Softmax(dim=-1)\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (relu): ReLU()\n",
       "    (conv_fuse): Sequential(\n",
       "      (0): Conv1d(1280, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "  )\n",
       "  (branch2): Branch(\n",
       "    (conv1): Conv1d(7, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (conv2): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (gather_local_0): Local_op(\n",
       "      (conv1): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (gather_local_1): Local_op(\n",
       "      (conv1): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (pt_last): StackedAttention(\n",
       "      (conv1): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (sa1): SA_Layer(\n",
       "        (q_conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (k_conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (v_conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "        (trans_conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "        (after_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU()\n",
       "        (softmax): Softmax(dim=-1)\n",
       "      )\n",
       "      (sa2): SA_Layer(\n",
       "        (q_conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (k_conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (v_conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "        (trans_conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "        (after_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU()\n",
       "        (softmax): Softmax(dim=-1)\n",
       "      )\n",
       "      (sa3): SA_Layer(\n",
       "        (q_conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (k_conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (v_conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "        (trans_conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "        (after_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU()\n",
       "        (softmax): Softmax(dim=-1)\n",
       "      )\n",
       "      (sa4): SA_Layer(\n",
       "        (q_conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (k_conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (v_conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "        (trans_conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "        (after_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU()\n",
       "        (softmax): Softmax(dim=-1)\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (relu): ReLU()\n",
       "    (conv_fuse): Sequential(\n",
       "      (0): Conv1d(1280, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "  )\n",
       "  (dp1): Dropout(p=0.5, inplace=False)\n",
       "  (relu): ReLU()\n",
       "  (linear1): Linear(in_features=2048, out_features=512, bias=False)\n",
       "  (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dp2): Dropout(p=0.5, inplace=False)\n",
       "  (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dp3): Dropout(p=0.5, inplace=False)\n",
       "  (linear3): Linear(in_features=256, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PairModel1().to(device)\n",
    "model.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if a want to load some pretrained weights\n",
    "W_stored = torch.load(r'C:\\\\Users\\\\Alessandro\\\\Desktop\\\\Tesi\\\\PairModel\\\\Check_points\\\\1117_145003_5.pt')\n",
    "model.load_state_dict(W_stored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:pnceapc8) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▃▂▃▃▂▁▄█▅▃▂▇</td></tr><tr><td>f1</td><td>▃▂▃▄▂▁▃█▅▃▃▇</td></tr><tr><td>f1_val</td><td>▁▁▁▁▃▄▅▆▇█</td></tr><tr><td>train_loss</td><td>▄██▆▅▆▆▁▂▃█▃</td></tr><tr><td>val_accuracy</td><td>▅▅▅▅▁▂▄▇▇█</td></tr><tr><td>val_loss</td><td>▃▅▆▄▇█▅▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.58</td></tr><tr><td>f1</td><td>0.56594</td></tr><tr><td>f1_val</td><td>0.56049</td></tr><tr><td>train_loss</td><td>0.72311</td></tr><tr><td>val_accuracy</td><td>0.56167</td></tr><tr><td>val_loss</td><td>0.68118</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">comic-bush-4</strong> at: <a href='https://wandb.ai/pair_fragments/train_lungo/runs/pnceapc8' target=\"_blank\">https://wandb.ai/pair_fragments/train_lungo/runs/pnceapc8</a><br/>Synced 6 W&B file(s), 0 media file(s), 10 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231205_111831-pnceapc8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:pnceapc8). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2599a4e0db0c49e5a39f1a8e6aa06583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011277777777932999, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Alessandro\\Desktop\\Tesi\\PairModel\\wandb\\run-20231205_114024-2rzqaem6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pair_fragments/train_lungo/runs/2rzqaem6' target=\"_blank\">legendary-galaxy-5</a></strong> to <a href='https://wandb.ai/pair_fragments/train_lungo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pair_fragments/train_lungo' target=\"_blank\">https://wandb.ai/pair_fragments/train_lungo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pair_fragments/train_lungo/runs/2rzqaem6' target=\"_blank\">https://wandb.ai/pair_fragments/train_lungo/runs/2rzqaem6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(\n",
    "      project=\"train_lungo\", \n",
    "      notes = \"tentativo con tante epoche e senza contrastive loss\",\n",
    "      config={\n",
    "      \"learning_rate\": 0.00005,\n",
    "      \"architecture\": \"Model2_mod\",\n",
    "      \"epochs\": 20,\n",
    "      \"weight_decay\": 0.0001,\n",
    "      \"W_crossentropy\":1,\n",
    "      \"W_contrastive\":0,\n",
    "      \"couples_per_epoch\": 10000,\n",
    "      \"seed\": seed # the seed defined at the beginning\n",
    "      })\n",
    "      \n",
    "config = wandb.config\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "contrast_criterion = ContrastiveLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay)\n",
    "num_epochs = config.epochs\n",
    "best_val_accuracy = 0.0 \n",
    "\n",
    "\n",
    "# Sets the path where the model weights will be stored.\n",
    "checkpoint_dir = r'C:\\\\Users\\\\Alessandro\\\\Desktop\\\\Tesi\\\\PairModel\\\\Check_points'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_interval = 1\n",
    "epoch_number = 0  \n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train() \n",
    "\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    random.shuffle(train_couples_0)\n",
    "    random.shuffle(train_couples_1)\n",
    "\n",
    "    \n",
    "    balanced_train_list = []\n",
    "    couples_per_epoch = config.couples_per_epoch\n",
    "\n",
    "    sampled_couples_0 = random.sample(train_couples_0, couples_per_epoch // 2)\n",
    "    sampled_couples_1 = random.sample(train_couples_1, couples_per_epoch // 2)\n",
    "\n",
    "    balanced_train_list.extend(sampled_couples_0)\n",
    "    balanced_train_list.extend(sampled_couples_1)\n",
    "        \n",
    "    random.shuffle(balanced_train_list)\n",
    "    \n",
    "    train_loader = DataLoader(balanced_train_list, batch_size=16,shuffle=True) \n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}', leave=False)\n",
    "\n",
    "    ###########\n",
    "    ## Train ##\n",
    "    ###########\n",
    "\n",
    "\n",
    "    for batch_data in progress_bar:\n",
    "\n",
    "        optimizer.zero_grad() \n",
    "        frags_a, frags_b, labels = batch_data\n",
    "        \n",
    "        \n",
    "        frags_a = apply_randomrotations(frags_a)\n",
    "        frags_b = apply_randomrotations(frags_b)\n",
    "        \n",
    "        frags_a = apply_translation(frags_a)\n",
    "        frags_b = apply_translation(frags_b)\n",
    "\n",
    "        frags_a = frags_a.double().to(device)\n",
    "        frags_b = frags_b.double().to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(frags_a, frags_b)\n",
    "        loss_ = criterion(outputs, labels)\n",
    "        \n",
    "        contrast_loss = contrast_criterion(frags_a, frags_b, labels)\n",
    "        loss = loss_ + config.W_contrastive*contrast_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_samples += labels.size(0)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "        progress_bar.set_postfix({'Loss': loss.item(), 'Accuracy': correct_predictions / total_samples})\n",
    "        \n",
    "\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    accuracy = correct_predictions / total_samples\n",
    "    train_loss = total_loss/len(train_loader)\n",
    "\n",
    "    metrics_train = {\"train_loss\": train_loss, \n",
    "                       \"accuracy\": accuracy,\n",
    "                       \"f1\":f1}\n",
    "    wandb.log(metrics_train) \n",
    "\n",
    "\n",
    "\n",
    "    ###############\n",
    "    ## Inference ##\n",
    "    ###############\n",
    "\n",
    "    model.eval()  \n",
    "    \n",
    "    val_loss_ = 0.0\n",
    "    val_correct_predictions = 0\n",
    "    val_total_samples = 0\n",
    "    val_contrast = 0.0\n",
    "    y_true_val = []\n",
    "    y_pred_val = []\n",
    "    with torch.no_grad():\n",
    "        for val_batch in val_loader_basic:\n",
    "            val_frags_a, val_frags_b, val_labels = val_batch\n",
    "            \n",
    "\n",
    "            val_frags_a = apply_translation(val_frags_a)\n",
    "            val_frags_b = apply_translation(val_frags_b)\n",
    "\n",
    "            val_frags_a = val_frags_a.double().to(device)\n",
    "            val_frags_b = val_frags_b.double().to(device)\n",
    "\n",
    "            val_labels = val_labels.to(device)\n",
    "            \n",
    "            val_outputs = model(val_frags_a, val_frags_b)\n",
    "            val_loss_ += criterion(val_outputs, val_labels).item()\n",
    "            val_contrast += contrast_criterion(val_frags_a, val_frags_b, val_labels).item()\n",
    "            val_loss = val_loss_ +config.W_contrastive*val_contrast\n",
    "            _, val_predicted = torch.max(val_outputs.data, 1)\n",
    "            val_total_samples += val_labels.size(0)\n",
    "            val_correct_predictions += (val_predicted == val_labels).sum().item()\n",
    "            y_true_val.extend(val_labels.cpu().numpy())\n",
    "            y_pred_val.extend(val_predicted.cpu().numpy())\n",
    "\n",
    "    f1_val = f1_score(y_true_val, y_pred_val, average='weighted')        \n",
    "    val_accuracy = val_correct_predictions / val_total_samples\n",
    "    val_loss /= len(val_loader_basic)\n",
    "    val_metrics = {\"val_loss\": val_loss, \n",
    "                       \"val_accuracy\": val_accuracy,\n",
    "                       \"f1_val\": f1_val}\n",
    "    wandb.log(val_metrics)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {train_loss:.4f}, Training Accuracy: {accuracy:.4f}, F1_train:{f1:.4f} ',\n",
    "    f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}, F1_val : {f1_val:.4f}')\n",
    "\n",
    "\n",
    "    # Store the results    \n",
    "    current_time = datetime.datetime.now()\n",
    "    checkpoint_name = f\"{current_time.strftime('%m%d_%H%M%S')}_{epoch + 1}.pt\"    \n",
    "    checkpoint_path = os.path.join(checkpoint_dir, checkpoint_name)\n",
    "    torch.save(model.state_dict(), checkpoint_path)\n",
    "    \n",
    "    # log the parameters \n",
    "    wandb.run.log_artifact(checkpoint_path,name=str(epoch+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try different validation set each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_1 = [[item[0], item[1],item[2]] for item in val_couples if item[2] == 1]\n",
    "val_0 = [[item[0], item[1],item[2]] for item in val_couples if item[2] == 0]\n",
    "\n",
    "\n",
    "\n",
    "val_loader_ =[]\n",
    "\n",
    "val_0_s = random.sample(val_0, 8500)\n",
    "val_1_s = random.sample(val_1, 1500)\n",
    "\n",
    "val_loader_.extend(val_0_s)\n",
    "val_loader_.extend(val_1_s)\n",
    "\n",
    "random.shuffle(val_loader_) \n",
    "\n",
    "val_loader_basic = DataLoader(val_loader_, batch_size=16)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load  pretrained weights\n",
    "W_stored = torch.load(r'C:\\\\Users\\\\Alessandro\\\\Desktop\\\\Tesi\\\\PairModel\\\\Check_points\\\\1204_195232_20.pt')\n",
    "model.load_state_dict(W_stored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6157\n"
     ]
    }
   ],
   "source": [
    "model.eval()  \n",
    "    \n",
    "val_loss_ = 0.0\n",
    "val_correct_predictions = 0\n",
    "val_total_samples = 0\n",
    "val_contrast = 0.0\n",
    "y_true_val = []\n",
    "y_pred_val = []\n",
    "with torch.no_grad():\n",
    "  for val_batch in val_loader_basic:\n",
    "    val_frags_a, val_frags_b, val_labels = val_batch\n",
    "            \n",
    "\n",
    "    val_frags_a = apply_translation(val_frags_a)\n",
    "    val_frags_b = apply_translation(val_frags_b)\n",
    "\n",
    "    val_frags_a = val_frags_a.double().to(device)\n",
    "    val_frags_b = val_frags_b.double().to(device)\n",
    "\n",
    "    val_labels = val_labels.to(device)\n",
    "            \n",
    "    val_outputs = model(val_frags_a, val_frags_b)\n",
    "    val_loss_ += criterion(val_outputs, val_labels).item()\n",
    "    val_contrast += contrast_criterion(val_frags_a, val_frags_b, val_labels).item()\n",
    "    val_loss = val_loss_ +config.W_contrastive*val_contrast\n",
    "    _, val_predicted = torch.max(val_outputs.data, 1)\n",
    "    val_total_samples += val_labels.size(0)\n",
    "    val_correct_predictions += (val_predicted == val_labels).sum().item()\n",
    "    y_true_val.extend(val_labels.cpu().numpy())\n",
    "    y_pred_val.extend(val_predicted.cpu().numpy())\n",
    "    \n",
    "f1_val = f1_score(y_true_val, y_pred_val, average='weighted') \n",
    "val_accuracy = val_correct_predictions / val_total_samples\n",
    "val_loss /= len(val_loader_basic)\n",
    "print(val_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
